{"NumericalAnalysis/CH1/index":{"title":"index","links":[],"tags":[],"content":""},"NumericalAnalysis/CH2/Band-matrix":{"title":"Band matrix","links":["NumericalAnalysis/CH2/LU-factorization","NumericalAnalysis/CH2/Band-matrix"],"tags":[],"content":"A is m\\times n\nDefinition\n(\\forall |j - i| &gt; b)a_{ij} = 0\nCosts\nStorage/solve cost is \\approx 2nb\nLU factorization cost for Band matrix is \\approx 2nb^2 operations"},"NumericalAnalysis/CH2/Cholesky-factorization":{"title":"Cholesky factorization","links":["NumericalAnalysis/CH2/LU-factorization","NumericalAnalysis/CH2/Symmetric-positive-definite-matrix"],"tags":[],"content":"This is a special case for LU factorization (U = L^T).\nA=LL^T\nwhere\n\nA m\\times n is SPD\n\n2x2 example\nL = \\begin{bmatrix} \nx &amp; 0 \\\\\ny &amp; z\n\\end{bmatrix}\nL^T = \\begin{bmatrix}\nx &amp; y \\\\\n0 &amp; z\n\\end{bmatrix}\nso\nA = LL^T = \\begin{bmatrix}\nx^2 &amp; xy \\\\\nxy &amp; y^2 + z^2\n\\end{bmatrix}\n\\square\nCosts\nOnly lower triangular part of A is accessed, so only \\frac{1}{2} the storage is required.\nOnly \\frac{n^3}{6} multiplications and additions required, so \\frac{1}{2} the work of LU factorization\nNo need to pivoting"},"NumericalAnalysis/CH2/Forward-backward-substitution":{"title":"Forward-backward substitution","links":["NumericalAnalysis/CH2/LU-factorization"],"tags":[],"content":"\nref: ubcmath.github.io/MATH307/systems/lu.html#forward-and-backward-substitution\n\nGiven A=LU by LU factorization, we can adapt this technique to solve Ax= b by Ly=b and Ux = y\nPython code example for LU factorization\nnp.linalg\nit is equivalent with codes:\ny = np.linalg.solve(L, b)\nx = np.linalg.solve(U, y)\ncustom implementation\nimport numpy as np\n \ndef fw_sub(L, b):\n    n = L.shape[0]\n    y = np.zeros((n, 1))\n    \n    for i in range(n):\n        sum_val = 0\n        for j in range(i):\n            sum_val += L[i, j] * y[j, 0]\n        y[i, 0] = (b[i, 0] - sum_val) / L[i, i]\n    \n    return y\n \ndef bw_sub(U, y):\n    n = U.shape[0]\n    x = np.zeros((n, 1))\n    \n    for i in range(n-1, -1, -1):\n        sum_val = 0\n        for j in range(i+1, n):\n            sum_val += U[i, j] * x[j, 0]\n        x[i, 0] = (y[i, 0] - sum_val) / U[i, i]\n    \n    return x\n \nL = np.array([\n\t[1, 0, 0],\n\t[2, 1, 0],\n\t[1, 1, 1]\n])\nU = np.array([\n\t[2, 4, 2],\n\t[0, 1, 1],\n\t[0, 0, 1]\n])\n \n# solve Ax = b\nA = L @ U\nb = np.array([[-1], [1], [2]])\nprint(f&quot;L={L}&quot;)\nprint(f&quot;U={U}&quot;)\nprint(f&quot;b={b}&quot;)\n# A=[[2 4 2]\n# [4 9 5]\n# [2 5 4]]\nprint(f&quot;A={A}&quot;)\n \n# solve Ly = b\ny = fw_sub(L, b)\n# solve Ux = y\nx = bw_sub(U, y)\n \n# y=[[-1.]\n#  [ 3.]\n#  [ 0.]]\nprint(f&quot;y={y}&quot;)\n# x=[[-6.5]\n#  [ 3. ]\n#  [ 0. ]]\nprint(f&quot;x={x}&quot;)\n# Ax=[[-1.]\n#  [ 1.]\n#  [ 2.]]\n# Ax should be eq to b\nprint(f&quot;Ax={A @ x}&quot;)\n "},"NumericalAnalysis/CH2/LU-factorization":{"title":"LU factorization","links":["NumericalAnalysis/CH2/Symmetric-positive-definite-matrix","NumericalAnalysis/CH2/Cholesky-factorization","NumericalAnalysis/CH2/Forward-backward-substitution"],"tags":[],"content":"factorizing by A = LU where L is lower triangular and U is upper triangular matrix.\nBasic factorization method\nMake all diagonal elements of L to one and manually calculate it with U.\n3x3 example\nL =\n\\begin{bmatrix}\n1 &amp; 0 &amp; 0\\\\\nx &amp; 1 &amp; 0 \\\\\ny &amp; z &amp; 1\n\\end{bmatrix}\nU =\n\\begin{bmatrix}\na &amp; b &amp; c \\\\\n0 &amp; d &amp; e \\\\\n0 &amp; 0 &amp; f\n\\end{bmatrix}\nSo we can say\nA =\n\\begin{bmatrix}\na &amp; b &amp; c \\\\\nxa &amp; xb + d &amp; xc + e \\\\\nya &amp; yb + zd &amp; yc + ze + f\n\\end{bmatrix}\n\\square\nMultiplying factorization method (like Gaussian elimination?)\nStarted with A = IA where I is identical matrix.\n3x3 example\n\\begin{eqs}\nA &amp;=\n\\begin{bmatrix}\n1 &amp; 0 &amp; 0 \\\\\n0 &amp; 1 &amp; 0 \\\\\n0 &amp; 0 &amp; 1\n\\end{bmatrix}\n\\begin{bmatrix}\na &amp; b &amp; c \\\\\nd &amp; e &amp; f \\\\\ng &amp; h &amp; i\n\\end{bmatrix}\\\\\n\n&amp;=\n\\begin{bmatrix}\n1 &amp; 0 &amp; 0 \\\\\n\\frac{d}{a} &amp; 1 &amp; 0 \\\\\n0 &amp; 0 &amp; 1\n\\end{bmatrix}\n\\begin{bmatrix}\na &amp; b &amp; c \\\\\n0 &amp; e - \\frac{bd}{a} &amp; f - \\frac{cd}{a} \\\\\ng &amp; h &amp; i\n\\end{bmatrix}\\\\\n\n\n&amp;=\n\\begin{bmatrix}\n1 &amp; 0 &amp; 0 \\\\\n\\frac{d}{a} &amp; 1 &amp; 0 \\\\\n\\frac{g}{a} &amp; 0 &amp; 1\n\\end{bmatrix}\n\\begin{bmatrix}\na &amp; b &amp; c \\\\\n0 &amp; e - \\frac{bd}{a} &amp; f - \\frac{cd}{a} \\\\\n0 &amp; h - \\frac{bg}{a} &amp; i - \\frac{cg}{a}\n\\end{bmatrix}\n\n\\end{eqs}\nthen eliminate h-\\frac{bg}{a} term by first or second row etc. \\square\nPartial Pivot\nExchange rows to let the biggest element in first row.\nGiven by the formula PA = LU.\nBut there are types that no need to pivot at all:\n\nDiagonally dominant\nSPD, where we can use Cholesky factorization instead\n\nApplications\nAfter factorization, we can solve Ax=b by Forward-backward substitution.\nBasically Ax = b is equivalent to x = A^{-1}b.\nSherman-Morrison\nx = (A - uv^T)^{-1}b = A^{-1}b + A^{-1}u(1 - v^TA^{-1}u)^{-1}v^TA^{-1}b\nWe can solve those A^{-1}b and A^{-1}u by Forward-backward substitution.\nCosts\ngenerally total cost in O(n^3)\\approx \\frac{2n^3}{3} operations\nBut after enable partial pivoting (only row exchange), total cost is O(n^2) &lt;&lt; \\frac{2n^3}{3}\nHowever for full pivoting, it is still O(n^3) for additional searching cost"},"NumericalAnalysis/CH2/Orthogonal-matrix":{"title":"Orthogonal matrix","links":["NumericalAnalysis/CH2/Orthogonal-matrix"],"tags":[],"content":"A is m\\times n\nDefinition\n\nA^TA=I and AA^T = I.\n\\det(A) = \\pm1\nA^{-1} = A^T\ncolumns of Orthogonal matrix are mutually orthogonal\nA^T is Orthogonal matrix\n"},"NumericalAnalysis/CH2/Symmetric-positive-definite-matrix":{"title":"Symmetric positive definite matrix","links":["NumericalAnalysis/CH4/Eigenvalue-and-Eigenvector"],"tags":[],"content":"A is m\\times n matrix\nDefinition\n\nA = A^T and (\\forall x \\neq 0) x^TAx &gt; 0.\nFor all 0 &lt; i &lt; n\n\nDiagonal entries a_{ii} &gt; 0\nEigenvalues \\lambda_i &gt; 0\nCondition number cond(A) = \\frac{\\max \\lambda}{\\min \\lambda}\n\n\n"},"NumericalAnalysis/CH2/index":{"title":"index","links":[],"tags":[],"content":""},"NumericalAnalysis/CH3/Hessenberg-matrix":{"title":"Hessenberg matrix","links":[],"tags":[],"content":"\nUpper:\nA is upper triangular with one additional nonzero diagonal below the main one: i &gt; j + 1 \\Longrightarrow A_{ij} = 0\nLower:\n"},"NumericalAnalysis/CH3/QR-factorization":{"title":"QR factorization","links":["NumericalAnalysis/CH2/Orthogonal-matrix","NumericalAnalysis/matrix","NumericalAnalysis/CH3/Hessenberg-matrix"],"tags":[],"content":"A = QR\nwhere:\n\nA is m\\times n\nR is square upper triangular matrix\nQ is Orthogonal matrix\nFeatures:\nQR factorization always exists but may not unique\nQR factorization only exists when Determinant is 0 and all diagonal elements &gt;0.\n\n\ngiven by numpy.linalg.qr\nSteps\nGram-Schmidt\n\nmost intuitive but not stable\nref: kwokanthony.medium.com/important-decomposition-in-linear-algebra-detailed-explanation-on-qr-decomposition-by-classical-3f8f5425915f\n\n\nfor column \\vec{a_i} in A, calculate u_i = a_i -(\\sum^{i-1}_{j=1} proj_{u_{j-1}} a_j) = a_i -(\\sum^{i-1}_{j=1} \\frac{a_j \\cdot u_{j-1}}{u_{j-1} \\cdot u_{j-1}} a_j).\nthen q_i = \\frac{u_i}{||u_i||} which is column in Q\nrepeat for all columns to get Q.\nR = Q^TA.\n\nHouseholder\n\nref: kwokanthony.medium.com/detailed-explanation-with-example-on-qr-decomposition-by-householder-transformation-5e964d7f7656\n\ncost O(n^3)\nSteps\n\ninit R_0 = A\nfor column \\vec{a_i} in A, calculate \\vec{v_i} = \\vec{a_i} \\pm ||\\vec{a_i}||_2e_i where e_1 is standard basis. Choose the sign to avoid cancellation.\nw_i = \\frac{\\vec{v_i}}{||\\vec{v_i}||}, Q_i = I - 2w_iw_i^T and R_i = Q_iR_{i - 1}.\nkeep this calculation column by column with only consider sub-matrix until R_i is upper right triangle matrix.\nQ = \\prod Q_i, R is last result of R_i.\n\n2x2 example\nA = \\begin{bmatrix}\n3 &amp; 7\\\\\n4 &amp; 2\n\\end{bmatrix}\n\\vec{v_1} = \\begin{bmatrix}3\\\\4\\end{bmatrix} \\pm \\sqrt{9 + 16} \\begin{bmatrix}1\\\\0\\end{bmatrix} = \\begin{bmatrix}8\\\\4\\end{bmatrix}\nw_1 = \\frac{1}{\\sqrt{64 + 26}}\\begin{bmatrix}8\\\\4\\end{bmatrix}\nQ_1 = I - 2w_1w_1^T = \\begin{bmatrix}\n-3/5 &amp; -4/5\\\\\n-4/5 &amp; 3/5\n\\end{bmatrix}\nThen\nR_1 = Q_1R_0 = Q_1A = \\begin{bmatrix}\n-5 &amp; -\\frac{29}{5}\\\\\n0 &amp; - \\frac{22}{5}\n\\end{bmatrix}\nSince R is already in right upper triangle matrix. We are done with R = R_1 and\nQ = Q_1 = \\begin{bmatrix}\n-\\frac{3}{5} &amp; -\\frac{4}{5}\\\\\n-\\frac{4}{5} &amp; \\frac{3}{5}\n\\end{bmatrix}\nIt’s consist with\n&gt;&gt;&gt; numpy.linalg.qr(np.matrix(&quot;3,7;4,2&quot;))  \nQRResult(Q=matrix([[-0.6, -0.8],  \n       [-0.8,  0.6]]), R=matrix([[-5. , -5.8],  \n       [ 0. , -4.4]]))\nGivens\n\nref: kwokanthony.medium.com/detailed-explanation-with-example-on-qr-decomposition-by-givens-rotation-6e7bf664fbdd\n\nG = \\begin{bmatrix}\n\\cos(\\theta) &amp; -\\sin(\\theta)\\\\\n\\sin(\\theta) &amp; \\cos(\\theta)\n\\end{bmatrix}\nFor higher dimensions, we need to use sth like\nG_{xy} = \\begin{bmatrix}\n\\cos(\\theta) &amp; -\\sin(\\theta) &amp; 0\\\\\n\\sin(\\theta) &amp; \\cos(\\theta) &amp; 0\\\\\n0 &amp; 0 &amp; 1\n\\end{bmatrix}\nG_{yz} = \\begin{bmatrix}\n1 &amp; 0 &amp; 0\\\\\n0 &amp; \\cos(\\theta) &amp; -\\sin(\\theta)\\\\\n0 &amp; \\sin(\\theta) &amp; \\cos(\\theta)\n\\end{bmatrix}\nG_{xz} = \\begin{bmatrix}\n\\cos(\\theta) &amp; 0 &amp; -\\sin(\\theta)\\\\\n0 &amp; 1 &amp; 0\\\\\n\\sin(\\theta) &amp; 0 &amp; \\cos(\\theta)\n\\end{bmatrix}\ndepend on which dimension.\nSteps\n\nFor column a_i in A, use G to build it to consist with right upper triangle matrix\ne.g. if we need to remove 2nd element in 3\\times 3 matrix, we need to use G_{xy} with cos(\\theta) = \\frac{x}{r} and \\sin(\\theta) = - \\frac{y}{r} where x is 1st element and y is the 2nd, and r = \\sqrt{x^2 + y^2}.\nThen get A_i = A_{i-1}G. Then check if we need to remove another element (like 3rd element) as well.\nRepeat this for all columns.\nQ = \\prod G_i^T, R is the last A_i.\n\nCosts\nif A is upper Hessenberg matrix, it only requires n Givens rotation.\notherwise O(n^2)."},"NumericalAnalysis/CH3/Singular-value-decomposition":{"title":"Singular value decomposition","links":["NumericalAnalysis/CH2/Orthogonal-matrix","NumericalAnalysis/CH4/Eigenvalue-and-Eigenvector"],"tags":[],"content":"A = U\\Sigma V^T\nwhere\n\nA is m\\times n\nU: An m\\times m Orthogonal matrix matrix whose columns are the left singular vectors of A.\n\\Sigma: A diagonal m\\times n matrix containing the singular values of A in descending order.\nV^T: The transpose of an n\\times n Orthogonal matrix where the columns are the right singular vectors of A.\n\nSteps\n\ncalculate AA^T\ncalculate Eigenvalues of AA^T by solving det(AA^T - \\lambda I) = 0, where I is identify matrix\nthen \\Sigma is \\delta from those \\lambda\ncalculate V right singular vectors(should be unit vectors), for each \\lambda, (A^TA - \\lambda I)v = 0\ncalculate U left singular vectors(should be unit vectors), for each \\lambda, (AA^T - \\lambda I)u = 0\n\n3x2 example\n\nref www.geeksforgeeks.org/singular-value-decomposition-svd/\n\nA=\\begin{bmatrix}\n1 &amp; 2 &amp; 3 \\\\\n3 &amp; 2 &amp; 1\n\\end{bmatrix}\nAA^T = \\begin{bmatrix}\n1 &amp; 2 &amp; 3 \\\\\n3 &amp; 2 &amp; 1\n\\end{bmatrix}\n\\begin{bmatrix}\n1 &amp; 3 \\\\\n2 &amp; 2 \\\\\n3 &amp; 1\n\\end{bmatrix}\n= \\begin{bmatrix}\n1 + 4 + 9 &amp; 3 + 4 + 3 \\\\\n3 + 4 + 3 &amp; 9 + 4 + 1\n\\end{bmatrix}\n= \\begin{bmatrix}\n14 &amp; 10\\\\\n10 &amp; 14\n\\end{bmatrix}\n\\det(AA^T - \\lambda I) =\n\\begin{bmatrix}\n14 - \\lambda &amp; 10 \\\\\n10 &amp; 14 - \\lambda\n\\end{bmatrix} = (14 - \\lambda)^2 - 10^2 = 14^2 - 28\\lambda + \\lambda^2 - 10^2 = \\lambda^2 - 28\\lambda + 96\n(\\lambda - 24)(\\lambda - 4) = 0\nThen we can get some \\lambda Eigenvalues, \\lambda_1 = 24 and \\lambda_2 = 4 and Singular value \\delta_1 = \\sqrt{24} and \\delta_2 = 2.\nwe can say\n\\Sigma = \\begin{bmatrix}\n\\delta_1 &amp; 0 &amp; 0 \\\\\n0 &amp; \\delta_2 &amp; 0\n\\end{bmatrix}\n= \\begin{bmatrix}\n\\sqrt{24} &amp; 0 &amp; 0 \\\\\n0 &amp; 2 &amp; 0\n\\end{bmatrix}\nFor each of them, calculate eigenvectors (A^TA - \\lambda I)v = 0\nwhere\nA^TA=\\begin{bmatrix}\n10 &amp; 8 &amp; 6 \\\\\n8 &amp; 8 &amp; 8 \\\\\n6 &amp; 8 &amp; 10\n\\end{bmatrix}\n(A^TA-24I)v_1 = \\begin{bmatrix}\n-14 &amp; 8 &amp; 6 \\\\\n8 &amp; -16 &amp; 8 \\\\\n6 &amp; 8 &amp; -14\n\\end{bmatrix}v_1 = 0\nRREF it\n\\begin{bmatrix}\n1 &amp; 0 &amp; -1 \\\\\n0 &amp; 1 &amp; -1 \\\\\n0 &amp; 0 &amp; 0\n\\end{bmatrix}v_1 = 0\nso x - z = 0 and y - z = 0\nv_1 = \\begin{bmatrix}\n\\frac{1}{\\sqrt{3}}\\\\\n\\frac{1}{\\sqrt{3}}\\\\\n\\frac{1}{\\sqrt{3}} \n\\end{bmatrix}\nso do \\lambda_2 = 4\n(A^TA-4I)v_2 = \\begin{bmatrix}\n6 &amp; 8 &amp; 6 \\\\\n8 &amp; 4 &amp; 8 \\\\\n6 &amp; 8 &amp; 6\n\\end{bmatrix}v_2 = 0\nRREF it\n\\begin{bmatrix}\n1 &amp; 0 &amp; 1 \\\\\n0 &amp; 1 &amp; 0 \\\\\n0 &amp; 0 &amp; 0\n\\end{bmatrix}\nso x + z = 0 and y = 0\nv_2 = \\begin{bmatrix}\n\\frac{1}{\\sqrt{2}} \\\\\n0 \\\\\n\\frac{-1}{\\sqrt{2}}\n\\end{bmatrix}\nThen for v_3, since it must perpendicular to v_1,v_2, we can say v_1^Tv_3 = 0 and v_2^Tv_3 = 0 is true. Solve these two equations to get v_3.\nv_3 = \\begin{bmatrix}\n\\frac{1}{\\sqrt{6}} \\\\\n-\\frac{2}{\\sqrt{6}} \\\\\n\\frac{1}{\\sqrt{6}}\n\\end{bmatrix}\nThen\nV =\\begin{bmatrix}\n*v_1 &amp; *v_2 &amp; *v_3\n\\end{bmatrix}\n=\\begin{bmatrix}\n\\frac{1}{\\sqrt{3}} &amp; \\frac{1}{\\sqrt{2}} &amp; \\frac{1}{\\sqrt{6}}\\\\\n\\frac{1}{\\sqrt{3}} &amp; 0 &amp; \\frac{-2}{\\sqrt{6}} \\\\\n\\frac{1}{\\sqrt{3}} &amp; \\frac{-1}{\\sqrt{2}} &amp; \\frac{1}{\\sqrt{6}}\\\\\n\\end{bmatrix}\nLastly need to find U with similar steps.\n(AA^T - 24I)u_1 = \\begin{bmatrix}\n-10 &amp; 10 \\\\\n10 &amp; -10\n\\end{bmatrix}u_1 = 0\nRREF it\n\\begin{bmatrix}\n-1 &amp; 1 \\\\\n0 &amp; 0 \\\\\n\\end{bmatrix}\nso u_1 = \\begin{bmatrix}\\frac{1}{\\sqrt{2}} \\\\ \\frac{1}{\\sqrt{2}}\\end{bmatrix}\n(AA^T - 4I)u_2 = \\begin{bmatrix}\n10 &amp; 10 \\\\\n10 &amp; 10\n\\end{bmatrix}u_1 = 0\nRREF it\n\\begin{bmatrix}\n1 &amp; 1 \\\\\n0 &amp; 0 \\\\\n\\end{bmatrix}\nso u_2 = \\begin{bmatrix}\\frac{1}{\\sqrt{2}} \\\\ \\frac{-1}{\\sqrt{2}}\\end{bmatrix}\nThen\nU = \\begin{bmatrix}*u_1 &amp; *u_2\\end{bmatrix} = \\begin{bmatrix}\n\\frac{1}{\\sqrt{2}} &amp; \\frac{1}{\\sqrt{2}} \\\\\n\\frac{1}{\\sqrt{2}} &amp; \\frac{-1}{\\sqrt{2}}\n\\end{bmatrix}\nTherefore\nA = U\\Sigma V^T = \\begin{bmatrix}\n\\frac{1}{\\sqrt{2}} &amp; \\frac{1}{\\sqrt{2}} \\\\\n\\frac{1}{\\sqrt{2}} &amp; \\frac{-1}{\\sqrt{2}}\n\\end{bmatrix}\n\\begin{bmatrix}\n\\sqrt{24} &amp; 0 &amp; 0 \\\\\n0 &amp; 2 &amp; 0\n\\end{bmatrix}\n\\begin{bmatrix}\n\\frac{1}{\\sqrt{3}} &amp; \\frac{1}{\\sqrt{2}} &amp; \\frac{1}{\\sqrt{6}}\\\\\n\\frac{1}{\\sqrt{3}} &amp; 0 &amp; \\frac{-2}{\\sqrt{6}} \\\\\n\\frac{1}{\\sqrt{3}} &amp; \\frac{-1}{\\sqrt{2}} &amp; \\frac{1}{\\sqrt{6}}\\\\\n\\end{bmatrix}^T\n\\square\nApplications\nPseudo Inverse (Moore-Penrose Inverse)\nM = U\\Sigma V^T"},"NumericalAnalysis/CH3/Vandermonde-matrix":{"title":"Vandermonde matrix","links":[],"tags":[],"content":"Definition\nMatrix A n\\times n has basis function t^i. Every term is t_i^j where j \\in [0, n - 1] and i \\in [1,n].\nExample\n&gt;&gt;&gt; import numpy\n&gt;&gt; numpy.vander([1, 2, 3, 4, 5], N=5, increasing=True)  \narray([[  1,   1,   1,   1,   1],  \n      [  1,   2,   4,   8,  16],  \n      [  1,   3,   9,  27,  81],  \n      [  1,   4,  16,  64, 256],  \n      [  1,   5,  25, 125, 625]])"},"NumericalAnalysis/CH3/index":{"title":"index","links":[],"tags":[],"content":""},"NumericalAnalysis/CH3/normal-equation":{"title":"normal equation","links":["NumericalAnalysis/CH3/pseudo-inverse-(Moore-Penrose-Inverse)","NumericalAnalysis/CH3/Vandermonde-matrix","NumericalAnalysis/CH3/normal-equation"],"tags":[],"content":"Definition\nSolution is\nx = (A^TA)^{-1}A^Tb\nIf (A^TA)^{-1} such inverse not exists, we need to use x \\approx A^+b from pseudo inverse (Moore-Penrose Inverse) to solve it.\nExample of solving polynomial\nf(x) = c_0 + c_1x + c_2x^2 + c_3x^3\nGiven vector x and f as input and output, we want to find c coefficients.\n\nbuild Vandermonde matrix\nSolve it by normal equation / pseudo inverse (Moore-Penrose Inverse)\n\n# build Vandermonde matrix\nA = np.vander(x, 4, True)\nc = la.solve(A.T @ f, A.T @ A)"},"NumericalAnalysis/CH3/pseudo-inverse-(Moore-Penrose-Inverse)":{"title":"pseudo inverse (Moore-Penrose Inverse)","links":["NumericalAnalysis/matrix","NumericalAnalysis/CH3/Singular-value-decomposition","NumericalAnalysis/CH3/normal-equation"],"tags":[],"content":"A no-square m \\times n matrix A usually has no inverse.\nBy Rank of matrix\n\nif rank(A) = n we can say A^+ = (A^TA)^{-1}A^T and cond(A) = ||A^T||_2 \\cdot ||A^+||_2.\nif rank(A) &lt; n, we can say cond(A) = \\infty.\nA simple construction method by Singular value decomposition is\n\nA^+ = V\\Sigma^+U^T\nwhere \\Sigma^+ is (\\forall \\delta \\in \\Sigma &gt; 0) \\delta^+ = \\frac{1}{\\delta}.\nApplications\nReplacing normal equation to solve polynomial when (A^TA) doesn’t have inverse: least squares solution of Ax \\approx b is given by x = A^+b."},"NumericalAnalysis/CH4/Eigenvalue-and-Eigenvector":{"title":"Eigenvalue and Eigenvector","links":[],"tags":[],"content":"Eigenvalues\n\nNotation: \\lambda\n\nsolve \\det(A - \\lambda I) = 0\ngiven by numpy.linalg.eighfor diagonal matrix and numpy.linalg.eig for non.\nSingular value\n\nNotation: \\delta\n\n\\delta^2 = \\lambda\nEigenvector\nAx = \\lambda x\nwhere x is Eigenvector and \\lambda is Eigenvalues.\nApplications\nProblem transformations\n\nShift, (A - \\sigma I)x = (\\lambda - \\sigma)x where \\sigma is scalar.\nInversion, A^{-1}x = \\frac{x}{\\lambda} if A nonsingular and x \\neq 0.\nPowers, A^kx = \\lambda^kx.\nPolynomial, p(A)x = p(\\lambda)x where p(t) is polynomial.\n\nExample\nFor A is symmetric matrix, e^A can be done by\ne^A = Xe^{\\lambda}X^T\nwhere X is Eigenvector matrix\nev, v = np.linalg.eigh(A)\nexpmA = v @ np.diag(np.exp(ev)) @ v^T"},"NumericalAnalysis/CH4/Similarity-Transformation":{"title":"Similarity Transformation","links":[],"tags":[],"content":""},"NumericalAnalysis/CH4/companion-matrix":{"title":"companion matrix","links":[],"tags":[],"content":""},"NumericalAnalysis/CH4/index":{"title":"index","links":[],"tags":[],"content":""},"NumericalAnalysis/index":{"title":"index","links":["NumericalAnalysis/readme"],"tags":[],"content":"readme"},"NumericalAnalysis/matrix":{"title":"matrix","links":["NumericalAnalysis/CH4/Eigenvalue-and-Eigenvector","NumericalAnalysis/CH2/Orthogonal-matrix","NumericalAnalysis/CH2/Symmetric-positive-definite-matrix","NumericalAnalysis/CH2/Band-matrix","NumericalAnalysis/CH3/Vandermonde-matrix","NumericalAnalysis/CH3/Hessenberg-matrix"],"tags":[],"content":"Operations of Matrix\nTranspose\nA^T and (AB)^T = B^TA^T\nConjugate transpose\nA^H\nDeterminant\n\\det(\n\\begin{bmatrix}\na &amp; b\\\\\nc &amp; d\n\\end{bmatrix}\n) = ad - cb\n\\det(\n\\begin{bmatrix}\na &amp; b &amp; c\\\\\nd &amp; e &amp; f \\\\\ng &amp; h &amp; i\n\\end{bmatrix}\n) = a(ei - fh) - b(di - fg) + c(dh - eg)\nProperties of Matrix\nRank\n\nThe rank of a matrix is equal to the number of non-zero rows if it is in Echelon Form.\n\nMultiplicity\nnumber of root appear in Eigenvalues\nTypes of Matrix\n\nDiagonal, (\\forall i,j) i \\neq  j \\Longrightarrow a_{ij} = 0.\nTridiagonal, (\\forall i,j)|i - j| &gt; 1 \\Longrightarrow a_{ij} = 0.\nTriangular, lower: (\\forall i,j)i &gt; j \\Longrightarrow a_{ij} = 0; higher: (\\forall i,j)i &lt; j \\Longrightarrow a_{ij} = 0.\nSymmetric, A=A^T.\nSkew-Symmetric, A=-A^T.\nHermitian, A = A^H.\nUnitary, A^HA = AA^H = I.\nNormal A=A^H; A^HA=AA^H.\nDefective, Multiplicity k &gt; 1 with fewer than k linearly independent corresponding Eigenvectors.\nNondefective / diagonalizable, it has X^{-1}AX = D where X is Eigenvectors.\n\n\n\nOrthogonal matrix, A^TA=AA^T=I.\nSymmetric positive definite matrix (SPD)\nBand matrix\nVandermonde matrix\nHessenberg matrix\n"},"NumericalAnalysis/readme":{"title":"readme","links":["NumericalAnalysis/matrix","NumericalAnalysis/CH2/LU-factorization","NumericalAnalysis/CH2/Cholesky-factorization","NumericalAnalysis/CH3/QR-factorization","NumericalAnalysis/CH3/Singular-value-decomposition","NumericalAnalysis/CH2/Forward-backward-substitution","NumericalAnalysis/CH3/normal-equation","NumericalAnalysis/CH4/Eigenvalue-and-Eigenvector","NumericalAnalysis/CH1/","NumericalAnalysis/CH2/","NumericalAnalysis/CH3/","NumericalAnalysis/CH4/"],"tags":[],"content":"This note is outcome of Spring 25 CS 450. Numerical Analysis in UIUC taught by instructor Paul Fischer.\nThe book is Scientific Computing: An Introductory Survey, Revised Second Edition.\nTopics by type\nTypes of Matrix\nFactorization:\n\nLU factorization\n\nCholesky factorization w/ SPD\n\n\nQR factorization based on orthogonal\nSingular value decomposition (SVD)\n\nSolving:\n\nForward-backward substitution w/ LU factorization\nnormal equation w/ Vandermonde matrix to solve polynomial\n\nEigenvalue problem:\n\nEigenvalue and Eigenvector\n\nTopics by Chapter\nChapter 1\nChapter 2\nChapter 3\nChapter 4"},"RealAnalysis/index":{"title":"index","links":["RealAnalysis/readme"],"tags":[],"content":"readme"},"RealAnalysis/integrableAndDiff/Darboux-integral":{"title":"Darboux integral","links":["RealAnalysis/integrableAndDiff/partition","RealAnalysis/sequences/bounded","RealAnalysis/sequences/convergent","RealAnalysis/integrableAndDiff/Riemann-integral"],"tags":[],"content":"Def 27.3\nfor partition \\delta \\subset [a, b]\n\n\\Delta_j = x_{j - 1} - x_j\n\\inf_I f = \\inf_{x \\in I} f(x) and \\sup_I f = \\sup_{x \\in I} f(x)\n\\underline{\\sum}_\\sigma = \\sum^{n - 1}_{j = 0} \\Delta_j \\inf_{I_j}f and \\overline{\\sum}_\\sigma = \\sum^{n - 1}_{j = 0} \\Delta_j \\sup_{I_j}f where I_j = [x_j, x_{j + i}]\n\nThm 29.1\nThen we can take I=\\lim_k \\overline{\\sum}_{\\tau_k} f  and \\tau_k = \\{x^k_j \\mid 0 \\leq j \\leq 2^k\\} where \\tau_k \\subset \\tau_{k + 1}.\nIndeed we can say \\overline{\\sum}_{\\tau_{k + 1}} \\leq \\overline{\\sum}_{\\tau_k} and (\\overline{\\sum}_{\\tau_k}) is bounded below and monotone decreasing, which imply it is convergent.\nRemarks:\n\nx^k_j means j-th element in x^k partition\nx^k partition means we evenly split it into 2^k elements\n\nLemma 28.2\nFor two partition \\sigma \\subset \\tau\n\\underline{\\sum}_\\sigma f \\leq \\underline{\\sum}_\\tau f \\leq R_\\tau(R, \\xi) \\leq \\overline{\\sum}_\\tau \\leq \\overline{\\sum}_\\sigma f\nwhere R is Riemann integral\nBasically, if the largest sub-interval is larger, we will get more inaccurate result.\nLemma 28.3\nFor two partition \\sigma \\subset \\tau , M = \\sup(f(x) - f(y)) which is the worst difference where a \\leq x, y \\leq b, we can say \\overline{\\sum}_\\tau \\leq \\overline{\\sum}_\\sigma f \\leq \\overline{\\sum}_\\tau + |\\tau| M(\\#\\tau - \\#\\sigma) where \\# is the number of that set."},"RealAnalysis/integrableAndDiff/Power-theory":{"title":"Power theory","links":["RealAnalysis/sequences/uniform-limit","RealAnalysis/sequences/continue","RealAnalysis/sequences/Metric-Space","RealAnalysis/sequences/convergent","RealAnalysis/integrableAndDiff/differentiable","RealAnalysis/integrableAndDiff/integrable"],"tags":[],"content":"Thm 37.1\nFor \\sum a_kx^k = f(x) we can prove\n\nf&#039;(x) = \\sum k a_k x^{k -1}\n\\int f(t) dt = \\sum \\frac{a_kx^{k+1}}{k+1}\n\nThm 37.2\nFor uniform limit \\lim f_n&#039; = g where g is continue and \\lim f_n = f point-wise, we can say f&#039;=g.\nThm 37.3\nFor \\lim f_n = f is uniform limit and \\lim f_n = f in Metric Space \\Longrightarrow \\lim \\int f_n(t) dt = \\int f(t) dt is uniform limit.\nDef 37.4 Cauchy-Hadamard theorem\nR = \\left[ \\lim_n \\sup \\sqrt[n]{|a_n|} \\right]^{-1}\nProps 37.5\n(\\forall r &lt; R) f_n(x) = \\sum^n_{k = 0} a_kx^k are uniformly Cauchy on C[-r,r]\nCor 37.6\n(\\forall r &lt; R) f_n uniformly converge to f on [-r, r] and \\sum a_kx^k convergent.\nLemma 37.7\n\\lim_n\\sup \\sqrt[n]{|a_n|} = \\lim_n\\sup\\sqrt[n]{(k+1)|a_{n+1}|}=\\lim_n\\sup\\sqrt[n]{\\frac{|a_{n-1}|}{k}}\nThm 37.8\nlet (a_n) and R=\\left( \\lim_n\\sup\\sqrt[n]{|a_n|}\\right)^{-1}\nThen on (-R, R), f(x) = \\sum_k a_kx^k is\n\nWell defined\ncontinue\ndifferentiable\nintegrable\n\nDef 38.1\n\\frac{1}{1-x} = \\sum^\\infty_{k=0} x^k\nRemark 38.2\n\nRadius of convergent comes from complex inequality.\n\nProp 38.3\n\\lim_k\\sup \\sqrt[k]{k} = 1"},"RealAnalysis/integrableAndDiff/Riemann-integral":{"title":"Riemann integral","links":["RealAnalysis/integrableAndDiff/Darboux-integral","RealAnalysis/integrableAndDiff/partition"],"tags":[],"content":"Def Def 28.1\nR(f, \\xi) = \\sum_j^{||\\xi||}\\Delta_j f(\\xi_j)\n\\sup R_\\sigma(f, \\xi) = \\overline{\\sum}_{\\sigma} f\nWhere \\overline{\\sum} is in Darboux upper sum\nDef 30.1\n\\lim_{n\\longrightarrow\\infty} \\frac{1}{n} \\sum^n_{j=1} f(a + j\\frac{b-a}{n}) = \\int^b_a f(x) dx\nOr\n\\lim_{n \\to \\infty} \\sum^{n-1}_{i=0} f(x_i)(x_{i+1}-x_i) = \\int^b_a f(x)dx\nBasically we just need the parition be small enough.\nLemma 30.2\n\nR(f + \\lambda g, \\xi) = R(f, \\xi) + \\lambda R(g, \\xi)\nfor [a, b] = [a, c] \\cup [c, b]\n\n\\sigma = \\sigma_{[a, c]} \\cup \\sigma_{[c, d]} where it’s partition\n\\Delta_{\\sigma_{[a,c] \\cup \\{c\\}}} + \\Delta_{\\sigma_{[c, b] \\cup \\{c\\}}} \\leq 2 \\Delta_\\sigma\n\n\n\nDef 10.2\n\\Delta_\\sigma(f) = \\sum (x_{j + 1} - x_j)(\\sup f - \\inf f)"},"RealAnalysis/integrableAndDiff/Trigonometry":{"title":"Trigonometry","links":["RealAnalysis/integrableAndDiff/differentiable"],"tags":[],"content":"Basic recall\n\n\\sin&#039;(x) = \\cos(x)\n\\cos&#039;(x) = -\\sin(x)\n\\sin(0) = 0, \\cos(0) = 1\n\\sin(\\frac{\\pi}{2})=1, \\cos(\\frac{\\pi}{2}) = 0\n\\sin(-x)=-\\sin(x)\n\nDef 41.1\n\\pi = \\sup\\{x \\mid \\forall 0 &lt; y &lt; x, \\cos(y) = \\infty\\}\nLemma 41.2\n|\\sin(x)| \\leq |x|\nproved by Thm 32.1 Fundamental Theorem and (\\forall t)\\cos(t)\\leq 1 with\n\\sin(x) - \\sin(0) = \\int^x_0 \\sin&#039;(t)dt = \\int^x_0 \\cos(t)dt \\leq x \\leq |x|\nThen\n-\\sin(x) = \\sin(-x) \\leq |x|\n\\square\nRemark 41.3\n1-\\cos(x) = \\int^x_0 \\sin(t)dt"},"RealAnalysis/integrableAndDiff/differentiable":{"title":"differentiable","links":["RealAnalysis/integrableAndDiff/differentiable","RealAnalysis/sequences/bounded","RealAnalysis/sequences/Lipschitz","RealAnalysis/integrableAndDiff/integrable","RealAnalysis/sequences/continue"],"tags":[],"content":"Def 31.3\nF is differentiable at x if\n(\\exists a)(\\forall \\varepsilon &gt; 0)(\\exists \\delta)|x - y| &lt; \\delta \\Longrightarrow |\\frac{F(y) - F(x)}{y - x} - a| &lt; \\varepsilon\nwhere we can say a =  F&#039;(x)\nThm 31.4\ndifferentiable f on (a, b) and f&#039;(x) bounded \\Longrightarrow f is Lipschitz\nThm 32.1 Fundamental Theorem\n\n\\int^x_ag&#039;(t)dt = g(x) - c\nif F&#039; is integrable, F(b) - F(a) = \\int^b_a F&#039;(t)dt\n\nThm 32.2 Mean Value Theorem(MVT)\nlet f be continue on [a,b] and f is differentiable on (a, b)\n(\\exists \\xi \\in (a,b)) \\frac{f(b) - f(a)}{b - a} = f&#039;(\\xi)\nRolle’s Lemma\nLet f be continue on [a, b] and differentiable on (a,b)\nf(a) = f(b) \\Longrightarrow (\\exists \\xi) f&#039;(\\xi) = 0\nRules\n\n(f + \\lambda g)&#039; = f&#039; + \\lambda g&#039;\n(f\\circ g)&#039; = (f&#039; \\circ g)g&#039;\n(fg)&#039; = f&#039;g + fg&#039;\nf \\in [a,b] is strict monotone, f^{-1} is continue\n\nThm 40.1 Chain rule\n(f\\circ g)&#039; = f&#039;(g(x))g&#039;(x)\nProp 40.1\nLet g: \\mathbb{R} \\longrightarrow \\mathbb{R}\n\\frac{d}{dy} \\int^b_a g(y,t)dt = \\int^b_a \\frac{d}{dy}g(y, t)dt\nThm 40.2 differential\nH&#039;(a) = \\lim_n \\frac{H(a + \\xi_n) - H(a)}{\\xi_n}\nThm\nInverse of differentiable function is differentiable.\nThm\n\\frac{f(x) - f(x_0)}{g(x)-g(x_0)} = \\frac{f&#039;(\\xi)}{g&#039;(\\xi)}\nx_0 &lt; \\xi &lt; x\nThm\nh&#039; is continue \\iff h is continue and differentiable."},"RealAnalysis/integrableAndDiff/integrable":{"title":"integrable","links":["RealAnalysis/sequences/bounded","RealAnalysis/integrableAndDiff/integrable","RealAnalysis/integrableAndDiff/partition","RealAnalysis/integrableAndDiff/mesh","RealAnalysis/sequences/continue","RealAnalysis/sequences/Lipschitz"],"tags":[],"content":"Def 28.5 pg. 228 Darboux integrable\nFor I = [a,b] and f:I \\longrightarrow \\mathbb{R} be a bounded function. Then f is Darboux integrable if (\\exists \\tau)(\\forall \\varepsilon &gt; 0)\\overline{\\sum}_\\tau f - \\underline{\\sum}_\\tau f &lt; \\varepsilon\nDef 28.1 Riemann integrable\n(\\exists I)(\\forall \\varepsilon &gt; 0)(\\exists \\delta)(\\exists \\sigma)(\\exists\\xi) |\\sigma| &lt; \\delta \\Longrightarrow |R(f, \\xi) - I| &lt; \\varepsilon\nwhere \\sigma is a partition, \\delta is the max mesh size, and \\xi is a set with points from every sub-interval in \\sigma, R is Riemann Sum.\nThm 28.4\nDarboux integrable imply Riemann integrable\nThm 29.5\nf continue imply f integrable\nLemma 10.4\nlet \\Phi be Lipschitz and f integrable, we have \\Phi \\circ f integrable.\nAlso \\Delta_\\sigma(\\Phi \\circ f) \\leq L \\Delta_\\sigma(f)\nThm 31.1 Lebesgue’s Criterion for Riemann Integrability\nf is bounded and \\exists k \\subseteq [a,b], the following are equivalent:\n\nf is Riemann integrable on k\nthe set of discontinuities of f on k has Lebesgue measure zero\nBasically, it means, f is only discontinue in measure zero set, and continue otherwise.\n\nThm 31.2\n\\varphi is continue, f integrable \\Longrightarrow \\varphi \\circ f integrable\nOH 35.1\nThm A\n\\varphi Lipschitz and f integrable \\Longrightarrow \\varphi \\circ f integrable\nThm B\n\\varphi continue and f integrable \\Longrightarrow \\varphi \\circ f integrable\nProof\nBy Thm C, we can say there exists S has Lebesgue Zero Measure.\nThm C\nf integrable \\iff (\\exists S) has Lebesgue Zero Measure"},"RealAnalysis/integrableAndDiff/integral":{"title":"integral","links":["RealAnalysis/integrableAndDiff/integrable","RealAnalysis/sequences/Lipschitz"],"tags":[],"content":"Def 29.3\n\\int^b_a f(x) dx = I = \\lim_k \\overline{\\sum}_{\\tau_k} f= \\lim R(f, \\xi)\nif f is integrable\nProp 29.4\n\\forall \\sigma\n\n\\underline{\\sum}_\\sigma f \\leq \\int ^b_a f(x) dx \\leq \\overline{\\sum}_\\sigma f\n| \\int^b_a f(x) dx | \\leq \\overline{\\sum}_\\sigma |f|\n|\\int^b_a f(x) dx| \\leq \\int_a^b |f(x)| dx\n\nThm 30.3\nfor f, g is integrable\n\n\\int^b_a (f(t) + \\lambda g(t))dt = \\int^b_a f(t)dt + \\lambda\\int^b_a g(t)dt\n\\int^b_af(t)dt = \\int^c_af(t)dt + \\int^b_c f(t)dt\n\nThm 30.5\n|\\int^b_a f dt| \\leq \\int^b_a |f| dt\nproved by considering \\Phi(y) = |y| as a Lipschitz function.\nDef 31.5\nBy Oresme\n\\int^1_0 x^mdx = \\frac{1}{m+1}\nProp 41.3\n\\int^b_a f(s) ds \\leq (b-a)\\sup_s f(s)"},"RealAnalysis/integrableAndDiff/mesh":{"title":"mesh","links":["RealAnalysis/integrableAndDiff/mesh","RealAnalysis/integrableAndDiff/partition"],"tags":[],"content":"Def pg. 200\nThe mesh (or norm) of partition is defined by\n|| \\mathcal{P} || = \\max\\{x_1 - x_0, x_2 - x_1, \\dots, x_n - x_{n - 1}\\}\nwhich is the largest length of all sub-interval"},"RealAnalysis/integrableAndDiff/partition":{"title":"partition","links":["RealAnalysis/sequences/closed","RealAnalysis/sequences/bounded","RealAnalysis/sequences/interval","RealAnalysis/integrableAndDiff/partition"],"tags":[],"content":"Def pg. 199\nFor a closed bounded interval [a, b], we can say \\mathcal{P}=\\{x_{i-1}, x_i\\}^n_{i=1}  is it’s partition where x_0 = a and x_n = b. By definition, we can say \\mathcal{P} is the set of points that split the [a, b] into many non-overlapped sub-interval."},"RealAnalysis/integrableAndDiff/proofs/Final-Review-problems":{"title":"Final Review problems","links":[],"tags":[],"content":"Radius\nfor f(x) = \\sum k^2 x^2\nR = \\lim_k \\sup \\sqrt[k]{|k^2|} \\Longrightarrow R=1 because\n\nk^{\\frac{2}{k}} \\geq 1 \\Longrightarrow R \\geq 1\nR \\leq 1 because\n(1 + \\varepsilon)^k \\geq (1+\\varepsilon k) \\Longrightarrow (\\exists k_0)(\\forall k \\geq k_0) (1+\\varepsilon)^k \\geq (1+k\\varepsilon) \\geq k^2\n\\square\n\nRiemann integral\nCalculate integral of \\lim_{a\\longrightarrow 1} \\sum cos(a^\\frac{j}{2})a^j(1-a)\nso mesh is like: x_0=1,x_1=a,x_j=a^j,x_N=0\nR_\\infty(f)=\\sum^\\infty_{j=0}f(a^j)(x_j-x_{j + 1}) where x_j - x_{j + 1} = a^j (1 - a)\ntake x_j = a^j = \\xi_j\nso\nR_\\infty(f, \\xi) = \\int^1_0 f(t) dt = \\int^1_0 \\cos(\\sqrt{x})dx\n\\square"},"RealAnalysis/integrableAndDiff/proofs/Problem-of-class-38":{"title":"Problem of class 38","links":["RealAnalysis/integrableAndDiff/Power-theory"],"tags":[],"content":"For\nf(z) = \\frac{1}{(z - i)(z + i)}\nconsider f(z) = \\frac{A}{z-i} + \\frac{B}{z + i} and solve A, B\nAnd it’s f(z) = \\frac{-i/2}{z-i} + \\frac{i/2}{z+i}.\nThen do Power theory:\nf(z) = \\frac{1}{2}\\left(\\frac{1}{1 - (\\frac{-z}{i})} + \\frac{1}{1-\\frac{z}{i}}\\right) = \\frac{1}{2}\\left[\\sum^\\infty_{k=0} (\\frac{-z}{i})^k + \\sum^\\infty_{k=0} (\\frac{z}{i})^k\\right]=\\sum^\\infty_{k=0} \\frac{z^{2k}}{i^{2k}}\n\\square"},"RealAnalysis/integrableAndDiff/proofs/Proofs-of-pi":{"title":"Proofs of pi","links":[],"tags":[],"content":"pi &gt;= 2\n\\cos(x) - 1 = - \\int^x_0 \\sin(t)dt\n\\Longrightarrow 2 = \\int^\\pi_0 \\sin(t) dt \\leq \\int^\\pi_0 t dt = \\frac{t^2}{2}\\bigg\\vert^\\pi_0 = \\frac{\\pi^2}{2}\n\\Longrightarrow 4 \\leq \\pi^2 \\Longrightarrow 2 \\leq \\pi\n\\square\npi &gt;= 2\\sqrt{2}\nThere is a simple way to do it with graph\n\nSo clearly, 2\\pi \\geq 4\\sqrt{2} \\Longrightarrow \\pi \\geq 2\\sqrt{2}"},"RealAnalysis/readme":{"title":"readme","links":["RealAnalysis/sequences/Cauchy-sequence","RealAnalysis/sequences/complete","RealAnalysis/sequences/closed","RealAnalysis/sequences/compact","RealAnalysis/sequences/connected","RealAnalysis/sequences/sequentially-Closed","RealAnalysis/sequences/sequentially-compact","RealAnalysis/sequences/continue","RealAnalysis/sequences/convergent","RealAnalysis/sequences/sequentially-continue","RealAnalysis/sequences/Lipschitz","RealAnalysis/sequences/bounded","RealAnalysis/sequences/totally-bounded","RealAnalysis/sequences/Delta-ball","RealAnalysis/sequences/Metric-Space","RealAnalysis/integrableAndDiff/integrable","RealAnalysis/integrableAndDiff/integral","RealAnalysis/integrableAndDiff/Darboux-integral","RealAnalysis/integrableAndDiff/Riemann-integral","RealAnalysis/integrableAndDiff/differentiable","RealAnalysis/integrableAndDiff/mesh","RealAnalysis/integrableAndDiff/partition","RealAnalysis/integrableAndDiff/proofs/Proofs-of-pi","RealAnalysis/sequences/proofs/3-lemmas-of-class-28","Bounded","RealAnalysis/sequences/proofs/proof-of-Thm-21.7","RealAnalysis/sequences/proofs/proof-of-Thm-15.1","RealAnalysis/integrableAndDiff/proofs/Final-Review-problems"],"tags":[],"content":"This note is outcome of Fall 24 Math 444. Elementary Real Analysis in UIUC, taught by professor Marius Junge.\nThe number after sub-heading indicates the number of class(e.g. Def 37.3 means 3rd point in lecture #37) and the book is Introduction to Real Analysis 4th Edition by Robert G. Bartle.\nTopics\nKey points for sequences:\n\nCauchy sequence\nCs for sets: complete, closed, compact, connected\nsequential version: sequentially Closed, sequentially compact\nC for functions: continue, convergent\nsequential version: sequentially continue\nuseful tools: Lipschitz, bounded and totally bounded, Delta-ball, Metric Space\n\nKey points for integrable:\n\nintegrable, integral\nDarboux integral and Riemann integral\ndifferentiable\nmesh and partition\n\nSome proofs:\n\n\\pi &gt;= 2 &gt;= 2\\sqrt{2} --- Proofs of pi\nSet S is totally bounded \\Longrightarrow S is bounded ---  3 lemmas of class 28\nSet S is compact \\Longrightarrow S is Bounded set --- proof of Thm 21.7\nFor Metric Space X(C,d), C is closed \\Longrightarrow X is complete --- proof of Thm 15.1\nRiemann integral of \\lim_{a\\longrightarrow 1} \\sum cos(a^\\frac{j}{2})a^j(1-a) --- Final Review problems\n"},"RealAnalysis/sequences/Cauchy-sequence":{"title":"Cauchy sequence","links":["RealAnalysis/sequences/convergent","RealAnalysis/sequences/complete","RealAnalysis/sequences/Metric-Space","RealAnalysis/sequences/Cauchy-sequence"],"tags":[],"content":"Def 14.1\n(x_{n}) is called Cauchy if\n(\\forall \\varepsilon &gt; 0)(\\exists n_0) (\\forall n, m &gt; n_0) d(x_n, x_m) &lt; \\varepsilon \nThm\nAll convergent sequence in complete Metric Space is Cauchy sequence."},"RealAnalysis/sequences/Delta-ball":{"title":"Delta-ball","links":[],"tags":[],"content":"Def 13.2\nB_\\delta(x) = \\{y \\mid d(x, y) \\leq \\delta \\}\nclosed \\delta ball around x\nB_\\delta(x) = \\{y \\mid d(x, y) &lt; \\delta \\}\nopen \\delta ball around x"},"RealAnalysis/sequences/Lipschitz":{"title":"Lipschitz","links":["RealAnalysis/sequences/Lipschitz","RealAnalysis/sequences/uniformly-continue","RealAnalysis/integrableAndDiff/differentiable","RealAnalysis/sequences/continue","RealAnalysis/sequences/bounded","RealAnalysis/integrableAndDiff/integrable"],"tags":[],"content":"Def 17.3\nf:(x, d) \\longrightarrow (y, d&#039;) is called Lipschitz\nif d(f(x), f(y)) \\leq k d(x, y)\nwhere k&gt;0 is called Lipschtz constant\nThm pg.143\nif f: A \\longrightarrow \\mathbb{R} is Lipschitz function, f is uniformly continue in A\nThm 24.1\nThe best(smallest) Lipschitz constant equal to the first order derivative of a differentiable function.\nOH 35.1\nThm D\nfor f continue, f&#039; bounded and f&#039; integrable \\Longrightarrow f Lipschitz\nProof\nby FT:\nf(b) - f(a) = \\int^b_a f&#039;(t)dt \\leq \\overline\\sum\\Delta\\sup f(\\xi) \\leq (b-a)\\sup_kf(\\xi_k)\nThm E\n\\exists f&#039; and f&#039; is bounded \\Longrightarrow f is Lipschitz\nProof\nby MVT\n(\\exists \\xi \\in (a,b)) \\frac{f(b) - f(a)}{b - a} = f&#039;(\\xi)\n\\Longrightarrow f(b) - f(a) = f&#039;(\\xi)(b-a) \\leq (b-a) \\sup f&#039;\nThm\nf uniformly continue \\Longrightarrow f Lipschitz"},"RealAnalysis/sequences/Metric-Space":{"title":"Metric Space","links":[],"tags":[],"content":"Def 13.1\n(X, d) is called metric space\n0) X is set\n\nd: X \\times X \\longrightarrow [0, \\alpha)\n\nd(x, y) = d(y, x)\nd(x, y) = 0 \\iff x = y\nd(x ,y) \\leq d(x, z) + d(z, y)\n\n\n\n3 standard choices of distance function 17.4\n\nd_\\infty(x, y) = \\max_d |x(d) - y(d)|\nd_2(x, y) = \\sqrt{\\sum_d |x(d) - y(d)|^2}\nd_1(x, y) = \\sum_{d=1}^d |x(d) - y(d)|\n"},"RealAnalysis/sequences/bounded":{"title":"bounded","links":["RealAnalysis/sequences/bounded","RealAnalysis/sequences/Delta-ball"],"tags":[],"content":"Def for R\nFor sequence (x_n), we can say it’s bounded if\n(\\exists M &gt; 0)(\\forall n \\in \\mathbb{N}) |x_n| &lt; M\nDef 23.5\nA set S \\in X is called bounded if there\n(\\exists R &gt; 0)(\\exists x \\in X) S \\subset B_R(x)\nWhere B_R is a Delta-ball.\nDef\nIf we say a function is bounded, we can say\n(\\exists M &gt; 0)(\\forall x)|f(x)| &lt; M"},"RealAnalysis/sequences/closed":{"title":"closed","links":["RealAnalysis/sequences/cluster-points","RealAnalysis/sequences/closed","RealAnalysis/sequences/sequentially-Closed"],"tags":[],"content":"Def\nA set is closed if\n\nIt’s complement set is open\nAll cluster points are in the set\n\nProp 15.2\nC \\subset X\nTFAE\n\nC is closed\nC is sequentially Closed\n"},"RealAnalysis/sequences/closure":{"title":"closure","links":["RealAnalysis/sequences/closed"],"tags":[],"content":"Def 17.1\n\\bar{S} = \\{\\lim_k x_k \\mid x_k \\in S \\} \\cup S\nis closure of set S, it has following properties\n\n\\bar{S} is closed\n\\bar{S} is smallest closed set which contain set S\n\nDef 18.1\nS is dense in \\bar{S}\n(\\forall y \\in \\bar{S})(\\exists x \\in S)(\\forall \\varepsilon &gt; 0) d(x, y) &lt; \\varepsilon"},"RealAnalysis/sequences/cluster-points":{"title":"cluster points","links":["RealAnalysis/sequences/cluster-points","RealAnalysis/sequences/Metric-Space","RealAnalysis/sequences/convergent"],"tags":[],"content":"Def pg.104\nFor set A \\subset \\mathbb{R}, if c \\in \\mathbb{R} is cluster point, we can say\n(\\forall \\varepsilon &gt; 0)(\\exists x \\neq c \\in A) |x - c| &lt; \\varepsilon\nBasically, for common Metric Space, it’s equivalent to the limit point."},"RealAnalysis/sequences/compact":{"title":"compact","links":["RealAnalysis/sequences/Metric-Space","RealAnalysis/sequences/open-cover","RealAnalysis/sequences/subcover","RealAnalysis/sequences/compact","RealAnalysis/sequences/totally-bounded","RealAnalysis/sequences/closed","RealAnalysis/sequences/sequentially-compact","RealAnalysis/sequences/continue","RealAnalysis/sequences/sequentially-continue","RealAnalysis/sequences/bounded"],"tags":[],"content":"Def pg.346 21.5\nA Metric Space (S, d) is compact if each open cover of S has finite subcover.\nLemma 21.6\nS is compact \\Longrightarrow totally bounded\nThm 21.7\nS \\subset (X, d) TFAE\n\nS compact\nS is closed, totally bounded\nS is sequentially compact\n\nThm 28 OH\nFor C \\subset X compact and continue function f: X \\longrightarrow \\mathbb{R}\n\n\\sup_{x \\in C} f(x) &lt; \\infty\n(\\exists x_0 \\in X) \\sup_{x \\in C} f(x) = f(x_0) according to every continue function reach it’s maximum.\n\nHeine–Borel theorem\nS \\subset \\mathbb{R}^d\n\nS is compact, where every open cover has finite subcover\nS is closed and bounded\n\nThm\nInverse image of compact set is compact."},"RealAnalysis/sequences/complete":{"title":"complete","links":["RealAnalysis/sequences/Metric-Space","RealAnalysis/sequences/complete","RealAnalysis/sequences/Cauchy-sequence","RealAnalysis/sequences/convergent","RealAnalysis/sequences/closed"],"tags":[],"content":"Def 14.2\nA metric space is complete if every Cauchy sequence in X is convergent to some points in the set X.\nThm 15.1\nFor X(C, d) a Metric Space\nTFAE\n\nC is closed\n(C, d) is complete\n\nThm 17.6 Existence of completion\nFor (X, d) is a Metric Space, then there exists a complete Metric Space \\underline{Y} and \\phi: X \\longrightarrow \\underline{Y}\n\nd_\\underline{Y}(\\phi(x), \\phi(y)) = d(x, y)\n\\phi(x) is dense in \\underline{Y}\n\nDef 18.3\ncompletion is unique(too complex to prove)"},"RealAnalysis/sequences/connected":{"title":"connected","links":["RealAnalysis/sequences/connected","RealAnalysis/sequences/open-set","RealAnalysis/sequences/interval","RealAnalysis/sequences/continue"],"tags":[],"content":"Def 19.1\nA set S is not connected if exists open set O_1, O_2 such that\n\nS \\subseteq O_1 \\cup O_2\nS \\land O_1 \\neq \\emptyset\nS\\land O_2 \\neq \\emptyset\nS \\cap O_1 \\cap O_2 = \\emptyset\n\nThm 19.2\nS \\subset \\mathbb{R} is connected \\iff S is interval\nThm 19.3\nfor f: X \\longrightarrow Y continue, S connected \\Longrightarrow f(S) connected\nThm Intermediate value 19.4\nf: [a, b] \\longrightarrow \\mathbb{R} be continue, y \\in [f(a), f(b)] \\Longrightarrow (\\exists a \\leq t \\leq b)p(t) = y"},"RealAnalysis/sequences/continue":{"title":"continue","links":["RealAnalysis/sequences/Metric-Space","RealAnalysis/sequences/continue","RealAnalysis/sequences/uniform-limit","RealAnalysis/sequences/sequentially-continue"],"tags":[],"content":"Def 16.1\nf is continue imply\n d(x, x&#039;) &lt; \\varepsilon \\Longrightarrow d(f(x), f(x&#039;)) &lt; \\varepsilon\nThm 16.2\nf is continue at x \\iff (\\lim_n x_n = x \\Longrightarrow \\lim_n f(x_n) = f(x))\nThm 16.3 17.2\nf: x \\longrightarrow y TFAE\n\nf is continuous\nit’s inverse image f^{-1}(O) is open for all open image O\n\nThm 17.5\nA Metric Space (X, d) and f, g \\in C(X, \\mathbb{R})\n\nf + g \\in C(X, \\mathbb{R})\nf\\times g \\in C(X, \\mathbb{R})\n\\exists \\phi: \\mathbb{R} \\longrightarrow \\mathbb{R} \\text{ c.t. } \\Longrightarrow \\phi \\circ f \\in C(X, \\mathbb{R})\nwhere C is the set of all continue functions from X to \\mathbb{R}\n\nThm 17.7\nThe uniform limit of continuous functions is continue\nThm\ncontinue \\iff sequentially continue\nThm 35.2\ninverse function of continue function is continue."},"RealAnalysis/sequences/convergent":{"title":"convergent","links":[],"tags":[],"content":"Def\n\\lim_n(x_n) = x&#039; \\iff (\\forall \\varepsilon &gt; 0)(\\exists n_0)(\\forall n \\geq n_0) |x_n - x&#039;| &lt; \\varepsilon"},"RealAnalysis/sequences/convex-set":{"title":"convex set","links":["RealAnalysis/sequences/convex-set","RealAnalysis/sequences/connected"],"tags":[],"content":"Cor 19.7\nconvex set \\Longrightarrow connected"},"RealAnalysis/sequences/interval":{"title":"interval","links":["RealAnalysis/sequences/interval"],"tags":[],"content":"five types:\n\nOpen\nClosed\nhalf-open/closed\ninfinity open\ninfinity closed\n\nDef pg.47\nIf (\\forall x,y \\in S) x &gt; y \\Longrightarrow [x, y] \\subseteq S is true, then S is interval."},"RealAnalysis/sequences/neighborhood":{"title":"neighborhood","links":[],"tags":[],"content":"Def pg. 326\nA neighborhood of a point x \\in \\mathbb{R} is any set V that contains an \\varepsilon-neighborhood V_\\varepsilon(x) := (x - \\varepsilon, x + \\varepsilon) of x for some \\varepsilon &gt; 0."},"RealAnalysis/sequences/open-cover":{"title":"open cover","links":["RealAnalysis/sequences/open-cover"],"tags":[],"content":"Def pg. 333\nlet A \\subset \\mathbb{R}, an open cover of A is a collection \\mathcal{G} = \\{G_\\alpha\\} where all G_\\alpha is open, such that\nA \\subseteq \\bigcup_\\alpha G_\\alpha"},"RealAnalysis/sequences/open-set":{"title":"open set","links":["RealAnalysis/sequences/open-set","RealAnalysis/sequences/neighborhood","RealAnalysis/sequences/closed"],"tags":[],"content":"Def 16.4\n\\emptyset is open\nDef pg. 327\n\nA subset G of \\mathbb{R} is open set in \\mathbb{R} if for each x \\in G there exits a neighborhood V of x that V \\subseteq G.\nA subset F of \\mathbb{R} is closed in \\mathbb{R} if the complement C(F) := \\mathbb{R} \\backslash F is open in \\mathbb{R}\n"},"RealAnalysis/sequences/path-connected":{"title":"path connected","links":["RealAnalysis/sequences/path-connected","RealAnalysis/sequences/continue","RealAnalysis/sequences/connected"],"tags":[],"content":"Def Path connected 19.5\nS \\subset X is path connected if x \\neq y \\in S (\\exists \\gamma: [0, 1] \\longrightarrow S) \\gamma continue and \\gamma(0) = x and \\gamma(1) = y\nThm 19.6\npath connected \\Longrightarrow connected\nExample\nwe can prove it’s path connected by manually making a path. e.g.\nf as upper bound and g as lower bound, we can make 3 paths and concat them.\n\ngo up to f from start x coordination\ngo through f to end x coordination\ngo down to end y coordination\n"},"RealAnalysis/sequences/proofs/3-lemmas-of-class-28":{"title":"3 lemmas of class 28","links":["RealAnalysis/sequences/totally-bounded","RealAnalysis/sequences/bounded"],"tags":[],"content":"Lemma 23.3\nFor set S \\subset X, S is totally bounded \\Longrightarrow S is bounded.\nSuppose S is totally bounded, we have\n(\\forall \\varepsilon &gt; 0)(\\exists m)(\\exists x_1, x_2, \\dots, x_m \\in X) \\bigcup^m_{\\alpha = 1} S \\subset B_\\varepsilon(x_\\alpha)\nand we want to prove that\n(\\exists R &gt; 0)(\\exists x \\in X) S \\subset B_R(x)\nThen take \\varepsilon = 1 and take x = x_\\alpha where \\alpha \\leq m, we can take R = \\max(\\{d(x_\\alpha, x_k) \\mid x_k \\in X \\}) which is the max distance between every points in X.\nAfter that, it’s safe to say S is bounded. \\square\nLemma 23.4\nFor set S \\subset \\mathbb{R}^d, S is bounded \\Longrightarrow S is totally bounded"},"RealAnalysis/sequences/proofs/Practice-of-exam-2":{"title":"Practice of exam 2","links":["RealAnalysis/sequences/closed","RealAnalysis/sequences/compact","RealAnalysis/sequences/bounded"],"tags":[],"content":"2. Closure is closed\nLet (x_n) \\subset \\mathbb{R}. Show that\nS = \\{x_n | n \\in \\mathbb{N}\\} \\cup Lim(x_n)\nis closed. Show that S is compact \\iff (x_n) is bounded.\nFirstly, we can prove S is closed by contradiction: suppose there exists (x_{n_j}) \\subseteq S such that \\lim(x_{n_j}) \\not\\in S, we have two cases:\n\nIf (x_{n_j}) \\subseteq (x_n),  it leads to a contradiction with lim(x_{n_j}) \\not\\in S due to Lim(x_n) \\subset S and \\lim(x_{n_j}) \\in Lim(x_n).\nIf A = (x_{n_j}) \\backslash (x_n) \\neq \\emptyset and \\lim(x_{n_j}) = x&#039;, we can say A \\subset Lim(x_n) and \\lim(x_{n_j}) = \\lim(A) \\in Lim(x_n) which leads to a contradiction with \\lim(x_{n_j}) \\not\\in S.\nHence in both cases we can say S is closed proved by contradiction. \\square\n"},"RealAnalysis/sequences/proofs/Problem-of-OH-after-class-28":{"title":"Problem of OH after class 28","links":["RealAnalysis/sequences/compact","RealAnalysis/sequences/continue"],"tags":[],"content":"For S \\subset X compact and a x \\not\\in S\nShow \\exists \\varepsilon &gt; 0, s.t.\n\\inf_{y \\in S} d(x, y) \\geq \\varepsilon &gt; 0\nThen according to d(x, y) is continue, we can say f(y) = -d(x, y) is also continue.\nAfter that we can say\n(\\exists y_0) \\sup_{y \\in S} f(y) = f(y_0)\nis true by Thm 28 OH. According to x \\not\\in S, we can say f(y_0) \\neq 0 is true.\nHence we can take \\varepsilon = d(x, y_0) and\n\\inf_{y \\in S} d(x, y) \\geq \\varepsilon = d(x, y_0) &gt; 0\nis true. \\square"},"RealAnalysis/sequences/proofs/proof-of-Thm-15.1":{"title":"proof of Thm 15.1","links":["RealAnalysis/sequences/complete","RealAnalysis/sequences/Metric-Space","RealAnalysis/sequences/closed","RealAnalysis/sequences/Cauchy-sequence","RealAnalysis/sequences/sequentially-Closed"],"tags":[],"content":"Thm 15.1\nFor X(C, d) a Metric Space\nproof 1 → 2\nSuppose C is closed, we want to prove X is complete.\nConsider (x_n) \\subseteq C as an arbitrary Cauchy sequence in C, according to C is closed, which imply C is sequentially Closed by Prop 15.2, we can say\n\\lim_n (x_n) = x&#039; \\Longrightarrow x&#039; \\in (x_n)\nis true. Hence it’s safe to say X is complete. \\square\nproof 2 → 1\nSuppose X is complete, we want to prove C is closed."},"RealAnalysis/sequences/proofs/proof-of-Thm-21.7":{"title":"proof of Thm 21.7","links":["RealAnalysis/sequences/compact","RealAnalysis/sequences/bounded","RealAnalysis/sequences/open-set","RealAnalysis/sequences/subcover"],"tags":[],"content":"Compact - Thm 21.7\nProof 1 → 2\nFor compact set K \\subseteq \\mathbb{R},\nBounded\nwe can prove it’s bounded at first by:\nConsider H_m = (-m, m) as an open set, then according to\nK \\subseteq \\bigcup_{m = 1}^\\infty H_m = \\mathbb{R}\nwe can say H_m is an subcover of K. According to K is compact, we can say (H_m) is finite. Then we have\nK \\subseteq \\bigcup_{m = 1}^M H_m = (-M, M)\nHence, we can say K is bounded by (-M, M).\n\\square\nClosed\nProof 3 → 2"},"RealAnalysis/sequences/sequentially-Closed":{"title":"sequentially Closed","links":["RealAnalysis/sequences/convergent"],"tags":[],"content":"Def 8.5\n[a, b] is sequentially closed imply\n(\\exists x = \\lim_n (x_n))(a \\leq x_n \\leq b) \\Longrightarrow a \\leq x \\leq b \\Longrightarrow x \\in [a, b]\nBasically, all limits of it’s sub-sequences are in itself."},"RealAnalysis/sequences/sequentially-compact":{"title":"sequentially compact","links":["RealAnalysis/sequences/Metric-Space","RealAnalysis/sequences/compact","RealAnalysis/sequences/sequentially-compact","RealAnalysis/sequences/closed"],"tags":[],"content":"\nfor common Metric Space, compact \\iff sequentially compact\n\nDef 20.1\nS \\subset (X, d) is called sequentially compact if every sequence has a convergence subsequence with limit in S\nLemma 20.2\nfor compact sequence S\nT \\subseteq S is closed \\Longrightarrow T is sequentially compact\nThm 20.3 21.1\nS \\subseteq \\mathbb{R}^d and sequence S compact or sequentially compact \\iff\n\nS is bounded\nS is closed\n"},"RealAnalysis/sequences/sequentially-continue":{"title":"sequentially continue","links":["RealAnalysis/sequences/sequentially-continue"],"tags":[],"content":"Def 7.6\nA function f: I \\longrightarrow \\mathbb{R} is called sequentially continue if\n(\\lim_n x_n = x) \\Longrightarrow (\\lim_n f(x_n) = f(x))\nThm 8.1\nAll sequentially continue function on [a, b] attain it’s maximum"},"RealAnalysis/sequences/subcover":{"title":"subcover","links":["RealAnalysis/sequences/open-cover","RealAnalysis/sequences/subcover"],"tags":[],"content":"Def pg. 333\n\nThe construction of \\mathcal{G} is in open cover\n\nIf \\mathcal{G}&#039; is a sub-collection of \\mathcal{G} such that it’s union also contain origin set A, then \\mathcal{G}&#039; is called subcover of \\mathcal{G}. If \\mathcal{G}&#039; has consist of finitely many set, we can call \\mathcal{G}&#039; a finite subcover of \\mathcal{G}.\nDef 21.4\nA subcover of open cover is an open cover"},"RealAnalysis/sequences/totally-bounded":{"title":"totally bounded","links":["RealAnalysis/sequences/totally-bounded","RealAnalysis/sequences/Delta-ball","RealAnalysis/sequences/bounded"],"tags":[],"content":"Def 21.1\nS \\subset X is totally bounded if\n(\\forall \\varepsilon &gt; 0)(\\exists m)(\\exists x_1, x_2, \\dots, x_m \\in X)\nS \\subset \\bigcup_{\\alpha = 1}^m B_\\varepsilon(x_\\alpha)\nwhere B_\\varepsilon is Delta-ball.\nThm 21.1\ntotally bounded \\Longrightarrow bounded"},"RealAnalysis/sequences/uniform-limit":{"title":"uniform limit","links":[],"tags":[],"content":"Def pg. 243\nA sequence of function (f_n) on A \\subseteq \\mathbb{R} to \\mathbb{R} converges uniformly on A_0 \\subseteq A to a function f: A_0 \\longrightarrow \\mathbb{R} if for all x \\in A_0\n(\\forall \\varepsilon &gt; 0)(\\exists K(\\varepsilon))(\\forall n \\geq K(\\varepsilon)) |f_n(x) - f(x)| &lt; \\varepsilon\nClaim 18.2\n\\lim_{n \\longrightarrow \\infty} d_\\infty(f_n, f) = 0"},"RealAnalysis/sequences/uniformly-continue":{"title":"uniformly continue","links":["RealAnalysis/sequences/uniformly-continue","RealAnalysis/sequences/interval","RealAnalysis/sequences/continue","RealAnalysis/sequences/Cauchy-sequence","RealAnalysis/sequences/compact","RealAnalysis/sequences/complete"],"tags":[],"content":"Def pg. 143\nlet A \\subseteq \\mathbb{R} and let f: A \\longrightarrow \\mathbb{R}.  We say f is uniformly continue if\n(\\forall \\varepsilon &gt; 0)(\\exists \\delta(\\varepsilon) &gt; 0)(\\forall x,u \\in A) d(x , u) &lt; \\delta(\\varepsilon) \\Longrightarrow d(f(x), f(u)) &lt; \\varepsilon\nThm Uniformly continuity theorem pg. 143\nLet I be a bounded closed interval and let f: I \\longrightarrow \\mathbb{R} be continue on I. Then f is uniformly continue on I.\nThm pg.144\nIf f: A \\longrightarrow \\mathbb{R} is uniformly continue on A \\subseteq \\mathbb{R} and if (x_n) is Cauchy sequence in A, then (f(x_n)) is Cauchy sequence in \\mathbb{R}\nThm 27.1\nFor f: C \\longrightarrow y is continue and C is compact, we can say f is uniformly continue.\nThm 27.2\nFor C compact, y complete, f: D \\longrightarrow y and D \\subset C is dense, TFAE:\n\nF: C \\longrightarrow y continue and F \\mid_D = f(means f is F when domain is restricted to D)\nf is uniformly continue\n"},"index":{"title":"index","links":["readme"],"tags":[],"content":"readme"},"readme":{"title":"readme","links":["RealAnalysis/readme","NumericalAnalysis/readme"],"tags":[],"content":"Real Analysis Readme, Math 444\nNumerical Analysis Readme, CS 450"}}